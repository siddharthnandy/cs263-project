{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "8WeVIFKVevHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfNfqt3-eixp"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_content = json.load(open('fine-tune-annotated.json'))"
      ],
      "metadata": {
        "id": "10Bxeq1Beyp-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "857215bc-646a-4b27-88fd-d646876a2bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'fine-tune-annotated.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e8175fb50e6b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjson_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fine-tune-annotated.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'fine-tune-annotated.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# messages = []\n",
        "f = open(\"fine-tuning-messages.jsonl\", \"a\")\n",
        "for entry in json_content:\n",
        "  prompt = entry['prompt']\n",
        "  rubric = entry['rubric']\n",
        "  essay = entry['essay']\n",
        "  score = entry['score']\n",
        "\n",
        "  system_content = f\"You are an essay scorer that is grading essays. Keep in mind they should spell correctly and poor spelling should be penalized with a lower score. Given a prompt, rubric and an essay you should return a single integer representing the score of the essay that is within the bounds of the rubric.\"\n",
        "  user_content = f\"\"\"Here is the rubric: {rubric}, prompt: {prompt}, and essay: {essay}.\n",
        "    Provide a single integer representing the score of the essay that is within the bounds of the rubric.\n",
        "  \"\"\"\n",
        "  assistant_content = score\n",
        "\n",
        "  system = {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": system_content\n",
        "  }\n",
        "\n",
        "  user = {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": user_content\n",
        "  }\n",
        "  assistant = {\n",
        "      \"role\": \"assistant\",\n",
        "      \"content\": assistant_content\n",
        "  }\n",
        "\n",
        "\n",
        "  # message = [system, user, assistant]\n",
        "  message = {\n",
        "      \"messages\": [system, user, assistant]\n",
        "  }\n",
        "  f.write(json.dumps(message))\n",
        "  f.write('\\n')\n",
        "f.close()"
      ],
      "metadata": {
        "id": "CB0lulP0e0xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyyOjhqueynO",
        "outputId": "8c5e0db4-9566-47e6-9bfd-1fae620582ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.30.3-py3-none-any.whl (320 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/320.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m225.3/320.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "zWXvLXXR3mbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "client.files.create(\n",
        "  file=open(\"fine-tuning-messages.jsonl\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "2V4OyxBMe1U_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7721a15f-95ac-489b-f750-7ef2491f3f09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FileObject(id='file-sCGW9tKdMCwtdRjkwx89PoM9', bytes=1090011, created_at=1716865851, filename='fine-tuning-messages.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.create(\n",
        "  training_file=\"file-sCGW9tKdMCwtdRjkwx89PoM9\",\n",
        "  model=\"gpt-3.5-turbo-0125\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfCbaI9r3eio",
        "outputId": "afb2c277-36a9-47f8-8136-ac5b44f253d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-yuqa7MxhDI1j4RtQLnFap98x', created_at=1716865921, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-C8yV2ACuxzOYfPp3V8KQMvB2', result_files=[], seed=397626080, status='validating_files', trained_tokens=None, training_file='file-sCGW9tKdMCwtdRjkwx89PoM9', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "system_content = f\"You are an essay scorer that is grading essays. Keep in mind they should spell correctly and poor spelling should be penalized with a lower score. Given a prompt, rubric and an essay you should return a single integer representing the score of the essay that is within the bounds of the rubric. Return a json object\"\n",
        "\n",
        "\n",
        "rubric = \"Rubric for Patience Essays:\\n\\n\\\"3\\\": \\\"Tells a story with ideas that are clearly focused on the topic and are thoroughly developed with specific, relevant details. Organization and connections between ideas and/or events are clear and logically sequenced. Command of language, including effective and compelling word choice and varied sentence structure, clearly supports the writer's purpose and audience. Consistent, appropriate use of conventions of Standard English for grammar, usage, spelling, capitalization, and punctuation for the grade level.\\\",\\n\\\"2\\\": \\\"Tells a story with ideas that are somewhat focused on the topic and are developed with a mix of specific and/or general details. Organization and connections between ideas and/or events are logically sequenced. Adequate command of language, including effective word choice and clear sentences, supports the writer's purpose and audience. Adequate use of conventions of Standard English for grammar, usage, spelling, capitalization, and punctuation for the grade level.\\\",\\n\\\"1\\\": \\\"Tells a story with ideas that are minimally focused on the topic and developed with limited and/or general details. Organization and connections between ideas and/or events are weak. Limited use of language, including lack of variety in word choice and sentences, may hinder support for the writer's purpose and audience. Limited use of conventions of Standard English for grammar, usage, spelling, capitalization, and punctuation for the grade level.\\\",\\n\\\"0\\\": \\\"Ideas are not focused on the task and/or are undeveloped. No organization evident. Ineffective use of language for the writer's purpose and audience. Ineffective use of conventions of Standard English for grammar, usage, spelling, capitalization, and punctuation.\"\n",
        "prompt = \"Prompt: Write about patience. Being patient means that you are understanding and tolerant. A patient person experience difficulties without complaining. Do only one of the following: write a story about a time when you were patient OR write a story about a time when someone you know was patient OR write a story in your own way about patience.\"\n",
        "essay = \"Some story about patience happened.\"\n",
        "\n",
        "model = \"ft:gpt-3.5-turbo-0125:personal::9TgLi0s0\"\n",
        "\n",
        "user_content = f\"\"\"Here is the rubric: {rubric}, prompt: {prompt}, and essay: {essay}.\n",
        "    Provide a single integer representing the score of the essay that is within the bounds of the rubric.\n",
        "\"\"\"\n",
        "response = client.chat.completions.create(\n",
        "  model=model,\n",
        "  response_format={ \"type\": \"json_object\" },\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": system_content},\n",
        "    {\"role\": \"user\", \"content\": user_content}\n",
        "  ]\n",
        ")\n",
        "print(response.choices[0].message)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us76J0ekz5eI",
        "outputId": "4a65eacd-bb3a-4c93-c065-55caad000766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='{\\n  \"score\": 2\\n}', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8pe-jCSW0MVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluation"
      ],
      "metadata": {
        "id": "poQ9Qxw6-mSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "id": "q5L0Oc08_5P1",
        "outputId": "226632a9-49d6-4e58-8d9f-36f2402e34ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.30.4-py3-none-any.whl (320 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/320.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/320.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import ast\n",
        "import pandas as pd\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "_4QCKkkl_37D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_eval_data = json.load(open('aggregated_annotations.json'))\n",
        "\n",
        "gold_scores = []\n",
        "given_scores = []\n",
        "\n",
        "\n",
        "# f = open(\"evaluation.json\", \"a\")\n",
        "\n",
        "for entry in json_eval_data:\n",
        "  prompt = entry['prompt']\n",
        "  rubric = entry['rubric']\n",
        "  essay = entry['essay']\n",
        "  gold_score = entry['score']\n",
        "\n",
        "  system_content = f\"You are an essay scorer that is grading essays. Keep in mind they should spell correctly and poor spelling should be penalized with a lower score. Given a prompt, rubric and an essay you should return a single integer representing the score of the essay that is within the bounds of the rubric. Return a json object with the key 'score' only\"\n",
        "\n",
        "\n",
        "  # rubric = \"Rubric for Patience Essays:\\n\\n\\\"3\\\": \\\"Tells a story with ideas that are clearly focused on the topic and are thoroughly developed with specific, relevant details. Organization and connections between ideas and/or events are clear and logically sequenced. Command of language, including effective and compelling word choice and varied sentence structure, clearly supports the writer's purpose and audience. Consistent, appropriate use of conventions of Standard English for grammar, usage, spelling, capitalization, and punctuation for the grade level.\\\",\\n\\\"2\\\": \\\"Tells a story with ideas that are somewhat focused on the topic and are developed with a mix of specific and/or general details. Organization and connections between ideas and/or events are logically sequenced. Adequate command of language, including effective word choice and clear sentences, supports the writer's purpose and audience. Adequate use of conventions of Standard English for grammar, usage, spelling, capitalization, and punctuation for the grade level.\\\",\\n\\\"1\\\": \\\"Tells a story with ideas that are minimally focused on the topic and developed with limited and/or general details. Organization and connections between ideas and/or events are weak. Limited use of language, including lack of variety in word choice and sentences, may hinder support for the writer's purpose and audience. Limited use of conventions of Standard English for grammar, usage, spelling, capitalization, and punctuation for the grade level.\\\",\\n\\\"0\\\": \\\"Ideas are not focused on the task and/or are undeveloped. No organization evident. Ineffective use of language for the writer's purpose and audience. Ineffective use of conventions of Standard English for grammar, usage, spelling, capitalization, and punctuation.\"\n",
        "  # prompt = \"Prompt: Write about patience. Being patient means that you are understanding and tolerant. A patient person experience difficulties without complaining. Do only one of the following: write a story about a time when you were patient OR write a story about a time when someone you know was patient OR write a story in your own way about patience.\"\n",
        "  # essay = \"Some story about patience happened.\"\n",
        "\n",
        "  model = \"ft:gpt-3.5-turbo-0125:personal::9TgLi0s0\"\n",
        "\n",
        "  user_content = f\"\"\"Here is the rubric: {rubric}, prompt: {prompt}, and essay: {essay}.\n",
        "      Provide a single integer representing the score of the essay that is within the bounds of the rubric.\n",
        "  \"\"\"\n",
        "  response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    temperature=.1,\n",
        "    response_format={ \"type\": \"json_object\" },\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": system_content},\n",
        "      {\"role\": \"user\", \"content\": user_content}\n",
        "    ]\n",
        "  )\n",
        "  # print(json.loads(response.choices[0].message.content)['score'])\n",
        "  given_score = json.loads(response.choices[0].message.content)['score']\n",
        "  json_entry = {\n",
        "      'prompt': prompt,\n",
        "      'rubric': rubric,\n",
        "      'essay': essay,\n",
        "      'score': gold_score,\n",
        "      'gptft_score': given_score\n",
        "  }\n",
        "\n",
        "  gold_scores.append(gold_score)\n",
        "  given_scores.append(given_score)\n",
        "#   f.write(json.dumps(json_entry))\n",
        "#   f.write(',\\n')\n",
        "# f.close()\n"
      ],
      "metadata": {
        "id": "tNpLlXzC-oWs"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "\n",
        "gold_scores = [int(item) for item in gold_scores]\n",
        "given_scores = [int(item) for item in given_scores]\n",
        "\n",
        "mae = mean_absolute_error(gold_scores, given_scores)\n",
        "mse = mean_squared_error(gold_scores, given_scores)\n",
        "# print(\"Mean Absolute Error:\", mae)\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9g_dsVKA8um",
        "outputId": "89e37412-d174-42af-8836-b3155dc481c6"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 1.0925925925925926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_eval_data = json.load(open('aggregated_annotations.json'))\n",
        "\n",
        "\n",
        "gpt_scores = []\n",
        "# f = open(\"evaluation.json\", \"a\")\n",
        "model = \"gpt-3.5-turbo\"\n",
        "\n",
        "for entry in json_eval_data:\n",
        "  prompt = entry['prompt']\n",
        "  rubric = entry['rubric']\n",
        "  essay = entry['essay']\n",
        "  gold_score = entry['score']\n",
        "\n",
        "  system_content = f\"You are an essay scorer that is grading essays. Keep in mind they should spell correctly and poor spelling should be penalized with a lower score. Given a prompt, rubric and an essay you should return a single integer representing the score of the essay that is within the bounds of the rubric. Return a json object in the format 'score': given_score\"\n",
        "\n",
        "\n",
        "\n",
        "  user_content = f\"\"\"Here is the rubric: {rubric}, prompt: {prompt}, and essay: {essay}.\n",
        "      Provide a single integer representing the score of the essay that is within the bounds of the rubric.\n",
        "  \"\"\"\n",
        "  response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    temperature=0.1,\n",
        "    response_format={ \"type\": \"json_object\" },\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": system_content},\n",
        "      {\"role\": \"user\", \"content\": user_content}\n",
        "    ]\n",
        "  )\n",
        "  # print(json.loads(response.choices[0].message.content)['score'])\n",
        "  given_score = json.loads(response.choices[0].message.content)['score']\n",
        "  json_entry = {\n",
        "      'prompt': prompt,\n",
        "      'rubric': rubric,\n",
        "      'essay': essay,\n",
        "      'score': gold_score,\n",
        "      'gpt_score': given_score\n",
        "  }\n",
        "\n",
        "  gpt_scores.append(given_score)\n",
        "\n",
        "#   f.write(json.dumps(json_entry))\n",
        "#   f.write(',\\n')\n",
        "# f.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "ENsc07rp_rFd"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_scores = [int(item) for item in gpt_scores]\n",
        "\n",
        "mae = mean_absolute_error(gold_scores, gpt_scores)\n",
        "mse = mean_squared_error(gold_scores, gpt_scores)\n",
        "# print(\"Mean Absolute Error:\", mae)\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-V_CeDhAH5J7",
        "outputId": "a5d9d69c-8732-4f99-ac4c-e5aacf7c96be"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.8333333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m_tgTvw6NQL6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}